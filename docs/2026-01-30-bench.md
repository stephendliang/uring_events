# Benchmark Results: io_uring HTTP Server

Tested on 2-core VPS

## Test Configuration

- **Tool**: wrk 4.2.0
- **Threads**: 2
- **Duration**: 20 seconds
- **Response**: "OK" (2 bytes)

---

## 2026-02-08 — Unified nolibc build

After eliminating all `#ifdef NOLIBC` conditionals (unified freestanding build).
Same 2-core VPS, same test parameters.

### 100 Connections

| Metric | Jan 30 (non-ZC) | Feb 8 (unified) | Delta |
|--------|-----------------|-----------------|-------|
| **Req/sec** | 73,570 | 104,753 | **+42.4%** |
| **Latency avg** | 1.30ms | 0.89ms | **-31.5%** |
| **Latency p50** | 1.31ms | 0.73ms | **-44.3%** |
| **Latency p99** | 3.38ms | 2.99ms | **-11.5%** |
| **Transfer/sec** | 6.31MB | 8.99MB | +42.5% |

### 500 Connections

| Metric | Jan 30 (non-ZC) | Feb 8 (unified) | Delta |
|--------|-----------------|-----------------|-------|
| **Req/sec** | 98,188 | 113,801 | **+15.9%** |
| **Latency avg** | 4.43ms | 3.48ms | **-21.4%** |
| **Latency p50** | 4.28ms | 3.41ms | **-20.3%** |
| **Latency p99** | 8.73ms | 8.18ms | **-6.3%** |
| **Transfer/sec** | 8.43MB | 9.77MB | +15.9% |

### Notes

Gains are cumulative from all commits since Jan 30 (buffer ring manager,
bitfield packing, cold-path split into uring.c, unified nolibc build),
not solely from the nolibc unification. Different VPS instance/kernel
version may also contribute.

---

## 2026-01-30 — Initial benchmark

### 100 Connections

| Metric | nginx 1.28.1 | io_uring (non-ZC) | io_uring (ZC) |
|--------|--------------|-------------------|---------------|
| **Req/sec** | 57,238 | 73,570 | 74,102 |
| **Latency avg** | 1.69ms | 1.30ms | 1.29ms |
| **Latency p50** | 1.85ms | 1.31ms | 1.30ms |
| **Latency p99** | 3.75ms | 3.38ms | 3.38ms |
| **Transfer/sec** | 8.13MB | 6.31MB | 6.36MB |

### 500 Connections

| Metric | nginx 1.28.1 | io_uring (non-ZC) | io_uring (ZC) |
|--------|--------------|-------------------|---------------|
| **Req/sec** | 73,738 | 98,188 | 100,541 |
| **Latency avg** | 6.34ms | 4.43ms | 4.31ms |
| **Latency p50** | 6.07ms | 4.28ms | 4.11ms |
| **Latency p99** | 11.68ms | 8.73ms | 8.46ms |
| **Transfer/sec** | 10.48MB | 8.43MB | 8.63MB |

### Analysis

#### io_uring vs nginx

| Connections | Throughput Gain | Latency Reduction |
|-------------|-----------------|-------------------|
| 100 | +29.5% | -23.7% avg, -9.9% p99 |
| 500 | +36.4% | -32.0% avg, -27.6% p99 |

#### Zero-Copy vs Non-ZC

| Connections | Throughput Gain | Latency Reduction |
|-------------|-----------------|-------------------|
| 100 | +0.7% | -0.8% avg |
| 500 | +2.4% | -2.7% avg, -3.1% p99 |

---

## Conclusions

1. **io_uring dominates nginx** by 30-36% in throughput and 24-32% in latency
2. **Cumulative optimizations** (Jan 30 to Feb 8) yielded +42% at 100c, +16% at 500c
3. **Zero-copy provides marginal benefit** (~2%) for tiny responses
4. **ZC advantage grows with load** - more visible at 500 connections
5. **ZC would shine with larger payloads** where kernel buffer copy cost matters

## Why io_uring Wins

- Single-threaded event loop (no process/thread overhead)
- Batched syscalls (multiple I/O ops per enter/exit)
- Multishot accept/recv (arm once, fire many)
- Provided buffer ring (zero userspace-kernel copies for recv)
- DEFER_TASKRUN (process completions in userspace context)

## Test Commands

```bash
# Build
make clean && make release

# Run server (pinned to CPU 0)
./event 8080 0 &

# Benchmark
wrk -t2 -c100 -d20s --latency http://127.0.0.1:8080/
wrk -t2 -c500 -d20s --latency http://127.0.0.1:8080/
```
